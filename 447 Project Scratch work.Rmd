---
title: "Predicting the Popularity of Different Beers"
author: "Eric Folsom, Delaney Green, Cameron Bayer, Eva Halsne"
date: "6/6/2023"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Team Name: Stout-asticians

## Dataset link: https://www.kaggle.com/datasets/rdoume/beerreviews

## Research Goal: 
The goal of this project is to predict the future popularity of beers given certain factors. We will be analyzing a dataset to determine which keywords, type, brand, aroma, style, appearance, taste and so forth affect what beers people prefer. Using this will we create predictions on beer popularity. 

## Abstract:

Beer and modern statistics share a surprising historical link. If it were not for William S. Gosset, a brewer at Guiness at the turn of the 20th century, we would not have Student's t-test, a hypothesis testing method that we use to this day. As statisticians from Washington state, which grows approximately three quarters of all the hops in the US, we have a natural interest in the creation and quality of beer. In this project, we use a dataset of ~1.5 million reviews from BeerAdvocate, one of the largest and oldest online resources for beer reviews, discussions, and events. By using a combination of classification and regression methods, our project takes a given beer and personal review to predict and recommend future beers to the reviewer.

\newpage



## Background:

Beer is one of the most popular alcoholic beverages in the world, with a global market worth billions of dollars. Understanding what factors contribute to the popularity of certain beers can be crucial for breweries and other businesses in the industry. With the rise of craft beer culture and the increasing number of beer options available, predicting what beers will be popular in the future can be a valuable tool for businesses looking to stay ahead of trends and improve their product offerings.
	Our goal is to use a dataset of beer reviews, to answer the following research question: What factors contribute to the popularity of different types of beers, and can we create a model to predict the future popularity of beers given these factors? Specifically, we will be analyzing the relationship between beer attributes such as keywords, type, brand, aroma, style, appearance, and taste, and the overall popularity of a beer as determined by user reviews. While treating our dataset as continuous we will use a mix of methods that are regression as well as classification, including, K-nearest neighbors, Lasso regression, and item based collaborative filtering methods to develop models that can predict future popularity based on these attributes.




## Methods: 

The dataset used for this project is a collection of user reviews and ratings for a myriad of beers. The dataset includes various attributes of the beers such as style, aroma, taste, appearance, and overall rating. We will be using this data to predict the popularity of beers based on these attributes. The original dataset contains over 1.5 million reviews in total. However, working with such a large quantity of data is computationally expensive, and as we preprocessed our data, we were able to reduce the number of reviews to around 56,000.
	To preprocess the data, we first removed any unnecessary columns to our research such as time of review, then converted categorical variables into dummy variables to be used in our models. Additionally, we wanted to reduce the size of our dataset without compromising the accuracy of a beer’s reviews by removing a subset of a given beer’s reviews. Therefore, we elected to take an average of all reviews for a unique beer in each category and use these values to create one data point. Thus, for each of the 56,857 unique beers in the dataset, there is one review that is representative of all given reviews in the original data. This reduces the size of our data set from 1.5 million to 56,857, which is somewhat more manageable for conducting analysis.
	We further separate each beer. There are 104 unique styles present in the data set, and we are creating graphs and performing analysis within each style of beer. One benefit to this is that our graphs will be easier to interpret (and also feasible to graph in R for some computers), and more significantly, this helps ensure our analysis is useful in application. For example, if a dark beer such as a Russian imperial stout has a high overall review rating, it would make sense to compare its taste and aroma to other dark beers of the same style to draw inferences about why it is well-liked instead of comparing it to a light lager beer, which often has a completely different flavor profile and should not be held to the same standards. Additionally, some beer drinkers may have strong preferences for beer styles, and to ensure they are recommended a beer they like; it is best to recommend beers within a style they enjoy.
	For classification, we will be using K-nearest neighbors (KNN). KNN works by identifying the k closest data points to a new observation and using the most common class among those k neighbors to predict the class of the new observation. 
We will also be using clustering methods to identify any natural groupings in the data. Specifically, we will use K-means clustering to group beers based on their attributes. K-means clustering works by assigning each observation to the nearest cluster center and iteratively updating the center until convergence.
Additionally, we will be using Lasso Regression. By doing so we can employ a shrinkage method which allows us to narrow down the suggestions in which our models give. In turn we have more accurate suggestions.
	Another facet of this model is the use of item based collaborative filtering. This encouraged the grouping of certain beers based on similar review scores, while narrowing the mass amount of data used.
	Overall, we will use a combination of clustering and regression methods to develop models that can accurately predict the popularity of beers based on their given scores. 


## Results:



\includegraphics[]{heatmap_plot.png}





## Limitations:

There are several limitations to consider in our project. Firstly, the reduction of the dataset from over 1.5 million reviews to about 45,000 may lead to a loss of valuable information. Although this reduction was necessary to handle computational limitations, it could potentially result in a less comprehensive analysis. 

Additionally, by taking the average of all reviews for a unique beer in each category, we create one representative data point per beer. While this helps reduce the dataset size, it overlooks potential variations within a beer's reviews, potentially oversimplifying the analysis. (We ended up not utilizing this new Total_Average variable, however, in a more detailed analysis in which this new column could be used, this would be a limitation.)

Furthermore, the choice of classification method, specifically K-nearest neighbors (KNN), and the use of Lasso regression introduce potential limitations. For example, KNN relies heavily on the choice of the number of neighbors (k) and the distance metric used, which can significantly impact the predictions. Regarding Lasso regression, it is a widely used method for feature selection and regularization. However, Lasso regression tends to shrink coefficients towards zero, leading to sparsity in the model and potentially overlooking important attributes. This can result in biased predictions and the exclusion of relevant variables from the model. 

These limitations should be taken into account when interpreting the results and may require further investigation or refinement of the methodology in future research.


\newpage
## References

\newpage
## Appendix

\includegraphics[]{versus review overall.png}

In the image seen above we have scatterplots comparing individual beer attributes to their overall score, this includes the ABV, aroma, apperance, palatte and taste. This was to identify if there were any highly correlated attributes to the overall review. 

\newpage

## R Code:







